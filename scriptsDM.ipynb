{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from math import log2\n",
    "import pandas as pd\n",
    "from statistics import variance, mean, mode\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Manhattan\n",
    "def manhattan_dist(p1: tuple,p2: tuple):\n",
    "    val = 0\n",
    "    for i in range(len(p1)):\n",
    "        val += abs(p1[i]-p2[i])\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Euclidean\n",
    "def euclidean_dist(p1: tuple,p2: tuple):\n",
    "    val = 0\n",
    "    for i in range(len(p1)):\n",
    "        val += (p1[i]-p2[i])**2\n",
    "    return math.sqrt(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chebyshev\n",
    "def chebyshev_dist(p1: tuple,p2: tuple):\n",
    "    return max([abs(p1[i]-p2[i]) for i in range(len(p1))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Min-Max-Norm\n",
    "def min_max_norm(l: list):\n",
    "    ma = max(l)\n",
    "    mi = min(l)\n",
    "    li = [(i - mi)/(ma-mi) for i in l]\n",
    "    return li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Z-Norm\n",
    "def z_norm(l: list):\n",
    "    v = variance(l)\n",
    "    m = mean(l)\n",
    "    li = [(i-m)/math.sqrt(v) for i in l]\n",
    "    return li"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#Call these functions with the arguments (ground-truth, prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entropy, Information Gain, Gain Ratio, Gini Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entropy and information gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entropy\n",
    "def entropy(entropy_row, class_row):\n",
    "    data = pd.concat([entropy_row, class_row], axis=1)\n",
    "    data.set_axis(['Entropy', 'Class'], axis=1, inplace=True)\n",
    "    data = data.groupby([l for l in data.columns]).size().reset_index(name='Count')\n",
    "\n",
    "    dic = {}\n",
    "    for val in entropy_row.unique():\n",
    "        d = data[data.Entropy == val]\n",
    "        l = sum(d[\"Count\"])\n",
    "        dic[val] = -sum([((i/l)*log2(i/l)) for i in d[\"Count\"]])\n",
    "\n",
    "    e = 0  \n",
    "    l = len(class_row)  \n",
    "    for i in class_row.value_counts():\n",
    "        e += (-(i/l)*log2(i/l))\n",
    "    return dic, e\n",
    "\n",
    "#Information Gain\n",
    "def inf_gain(entropy_row, class_row):\n",
    "    ent, whole_set = entropy(entropy_row,class_row)\n",
    "    l = len(entropy_row)\n",
    "    t = entropy_row.value_counts()\n",
    "    \n",
    "    for val in entropy_row.unique():\n",
    "        whole_set -= ((t[val]/l)*ent[val])\n",
    "\n",
    "    return whole_set\n",
    "\n",
    "d = {'Genre': [\"Action\", \"Action\", \"Action\", \"Adventure\",\"Adventure\", \"Adventure\",\"Adventure\", \"Adventure\",\"Adventure\", \"Adventure\"],\n",
    "    'Buy': [\"No\",\"No\",\"No\",\"Yes\",\"Yes\",\"No\",\"No\",\"Yes\",\"Yes\",\"No\"]}\n",
    "df = pd.DataFrame(data=d)\n",
    " \n",
    "#inf_gain(df.Genre, df.Buy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gain ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gini index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_matrix(data, dist_type):\n",
    "    data_ex_class = [p[:-1] for p in data]\n",
    "    mat = [[] for i in range(len(data))]\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        for j in range((i),len(data)):\n",
    "            if i == j:\n",
    "                #Not \"Correct\" with inf, but we want to find minimum in the next step, excluding distance to self\n",
    "                mat[i].append(math.inf)\n",
    "            else:\n",
    "                d = dist_type(data_ex_class[i],data_ex_class[j])\n",
    "                mat[i].append(d)\n",
    "                mat[j].append(d)\n",
    "    \n",
    "    return mat\n",
    "\n",
    "def find_k_min(d_matr, k):\n",
    "    mat = d_matr.copy()\n",
    "    l = []\n",
    "    for i in range(len(mat)):\n",
    "        x = np.array(mat[i]).argsort()[:k]\n",
    "        l.append(x)\n",
    "    return l\n",
    "\n",
    "def k_nn(data, k, dist_type): \n",
    "    d_matr = distance_matrix(data, dist_type)\n",
    "    indexes = find_k_min(d_matr, k)\n",
    "    class_at_ind = [[data[i][-1] for i in j] for j in indexes]\n",
    "    pred = [max(set(class_at_ind[i]), key=class_at_ind[i].count) for i in range(len(class_at_ind))]\n",
    "    return pred\n",
    "    \n",
    "\n",
    "#(coord, ..., coord, class)\n",
    "#data = [(1,0.4,0), (1.3,-0.4,0),(1.1,0.8,0),(1,-2,0),(-0.1,0,0),(0,0.3,1),(-0.6,0.9,1),(-1.4,-1.4,1),(-1.3,-0.2,1),(-1,1.5,1)]\n",
    "#k_nn(data, 3, manhattan_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NaÃ¯ve Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k-Means and SSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({(2.0, 2.0): [(2, 2)],\n",
       "  (5.0, 7.0): [(4, 6), (4, 8), (6, 6), (6, 8)],\n",
       "  (8.0, 0.0): [(8, 0)]},\n",
       " 16.0,\n",
       " 3)"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def dist_cent_point(data, centroids, dist_type):\n",
    "    l = [[] for i in range(len(data))]\n",
    "    for i in range(len(centroids)):\n",
    "        for j in range(len(data)):\n",
    "            l[j].append(dist_type(data[j],centroids[i]))\n",
    "    return l\n",
    "\n",
    "#Returns the new centroid with the points associated\n",
    "def compute_centroids_points(data, dist,median):\n",
    "    d = [[] for i in range(len(dist[0]))]\n",
    "    for i in range(len(data)):\n",
    "\n",
    "        ### THIS SHOULD BE AMENDED TO PURSUE EACH PATH AND FIND THE ONE WITH LOWEST SSE ###\n",
    "        ### Dilemma: Spend time fixing, or just run ~ 100 times and pick solution with lowest SSE? ###\n",
    "        ind = random.choice(np.where(np.array(dist[i]) == np.array(dist[i]).min())[0])\n",
    "\n",
    "        d[ind].append(data[i])\n",
    "    dic = {}\n",
    "    for points in d:\n",
    "        if median:\n",
    "            x = np.median(points, axis=0)\n",
    "        else:\n",
    "            x = np.average(points, axis=0)\n",
    "        dic[tuple(x)] = points \n",
    "    return dic\n",
    "\n",
    "def sse(centroids_with_points: dict, dist_type):\n",
    "    s = 0 \n",
    "    for key,vals in centroids_with_points.items():\n",
    "        for val in vals:\n",
    "            s += dist_type(key,val)**2\n",
    "    return s\n",
    "    \n",
    "#returns result in i iterations\n",
    "def k_means(data, centroids_or_k, dist_type, median):\n",
    "    if type(centroids_or_k) == int:\n",
    "        centroids = random.sample(data,centroids_or_k)\n",
    "    else: \n",
    "        centroids = centroids_or_k\n",
    "    i = 0\n",
    "    while True:\n",
    "        dist = dist_cent_point(data, centroids, dist_type)\n",
    "        new_c_p = (compute_centroids_points(data,dist,median))\n",
    "        i += 1\n",
    "        new_centroids = [i for i in new_c_p.keys()]\n",
    "        if set(new_centroids) == set(centroids):\n",
    "            return new_c_p, i\n",
    "        centroids = [i for i in new_c_p.keys()]\n",
    "        \n",
    "#Because of randomness in picking between ties --> run n times \n",
    "def k_means_runner(data, centroids_or_k, dist_type, n, median):\n",
    "    sol = (None,math.inf,0) #(Solution, SSE, Iterations)\n",
    "    #Iterations to run given by num\n",
    "    for i in range(n):\n",
    "        r,i = k_means(data,centroids_or_k,manhattan_dist, median=True)\n",
    "        s = sse(r,manhattan_dist)\n",
    "        if s < sol[1]:\n",
    "            sol = (r,s,i) \n",
    "    return sol\n",
    "\n",
    "\n",
    "# median decides how to compute new centroid --> TRUE: Median, FALSE: AV\n",
    "data = [(2,2),(4,6),(4,8),(6,6),(6,8),(8,0)]\n",
    "centroids = [(4,6),(4,8),(6,6)]\n",
    "k_means_runner(data,centroids,manhattan_dist, 50, median=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RUN BLOCK (RUN ALL FIRST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "24cd5c2f30858a0d9bc1d12d892ca26d1a556e72a0d5b4289d39a1c46964c99a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
